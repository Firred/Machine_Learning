{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Alumnos**: *Arturo Barbero Pérez y Adrián Ogáyar Sanchez*\n",
    "\n",
    ">**Grupo**: *11*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESIÓN LOGÍSTICA MULTI-CLASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZACIÓN DE LOS DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerías que van a ser necesarias durante el desarrollo de la práctica: La librería **Pyplot** es necesaría para poder hacer el graficado de los números contenidos en la matriz de datos. **NumPy** es la librería que nos permite realizar calculos entre matrices y vectores de manera de más eficiente gracias a la vectorización. Importamos además **loadmat** que se va a encargar de obtener los datos del fichero mat. Por último, utilizamos **Optimize** de SciPy, que nos permite obtener el vector θ optimizado para cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('ex3data1.mat')\n",
    "\n",
    "# se pueden consultar las claves con data.keys()\n",
    "y = data['y']\n",
    "X = data['X']\n",
    "# almacena los datos leídos en X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El fichero *ex3data1.mat* contiene 5000 ejemplos de entrenamiento en formato nativo para matrices de Octave/Matlab. El fichero se carga con la función loatmat que devuelve un diccionario del que podemos extraer las matrices *X* e *y*. \n",
    "Cada ejemplo de entrenamiento es una imagen de 20x20 pixeles donde cada píxel está representado por un número real que indica la intensidad en escala de grises de ese punto. Cada matriz de 20x20 se ha desplegado en un vector de 400 elementos que ocupa una fila de la matriz X. De esta forma X es una matriz de orden 5000x400."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 199.5, 19.5, -0.5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Selecciona aleatoriamente 10 ejemplos de entrenamiento y los pinta\n",
    "\n",
    "sample = np.random.choice(X.shape[0], 10)\n",
    "plt.imshow( X[ sample, :].reshape(-1, 20).T)\n",
    "plt.axis ('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VECTORIZACIÓN DE LA REGRESIÓN LOGÍSTICA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorización de la función de coste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor de la función de coste (sin regularizar) en regresión logística viene dado por la siguiente expresión:\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m}[ -y^{(i)} log(h_\\theta(x^{(i)})) - (1 - y^{(i)}) log(1 - h_\\theta(x^{(i)})) ]$$\n",
    "\n",
    "Donde *m* es el número de ejemplos de entrenamiento y $h_\\theta$ es la función sigmoide que viene dada por la expresión:\n",
    "\n",
    "$$g(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "La función de coste podemos darla vectorizada con los siguientes cálculos:\n",
    "\n",
    "\n",
    "$$J(\\theta) = - \\frac{1}{m}{((log( g(X\\theta) ))^{T}y) + (log(1 - g(X\\theta)))^{T}(1-y))}$$\n",
    "\n",
    "\n",
    "De esta manera, el sumatorio es más fácil de calcular ya que las multiplicaciones se realizan entre matrices, siendo así de una manera más rápida. Mediante este método nos ahorramos la necesidad de bucles, ayudados de la multiplicación elemento a elemento y la función sumatorio.\n",
    "\n",
    "Pasemos a declarar las funciones necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda z: 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funCoste(theta, x, y):\n",
    "    return -1/len(x) * (((np.log( g(x.dot(theta)) )).T).dot(y) + \n",
    "                        ((np.log( 1 - g(x.dot(theta)) )).T).dot(1-y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorización del gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El gradiente de la función de coste (sin regularizar) es un vector de la misma longitud de $\\theta$ donde la componente *j* viene dada por la expresión:\n",
    "\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial \\theta} = \\frac{1}{m} \\sum_{i=1}^{m}( h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}_j$$\n",
    "\n",
    "Pudiendo darla vectorizada de la siguiente manera:\n",
    "\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial \\theta} = \\frac{1}{m}{ X^{T} (g(X\\theta) - y)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(theta, x, y):\n",
    "    return 1/len(x) * (x.T).dot(g(x.dot(theta)) - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorización de la versión regularizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos ahora el término de regularización de la función de coste vectorizada y el gradiente de la regresión logística\n",
    "\n",
    "\n",
    "$$J(\\theta) = [ \\frac{1}{m} \\sum_{i=1}^{m}[ -y^{(i)} log(h_\\theta(x^{(i)})) - (1 - y^{(i)}) log(1 - h_\\theta(x^{(i)})) ] + \\frac{\\lambda}{2m} \\sum_{j=1}^{n} \\theta^{2}_j ] $$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(\\theta)}{\\partial\\theta_j} = \\begin{cases}\n",
    "\\frac{1}{m} \\sum_{i=1}^{m}( h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}_j\n",
    "& \\mbox{si $j=0$,}\\\\\n",
    "(\\frac{1}{m} \\sum_{i=1}^{m}( h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}_j) + \\frac{\\lambda}{m}  \\theta_j & \\mbox{si $j >= 1$}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Dadas vectorizadas respectivamente de la siguiente manera:\n",
    "\n",
    "$$J(\\theta)= \\frac{-1}{m} ((log(g(X\\theta)))^Ty+log(1-g(X\\theta)))^T(1-y)+\\frac{\\lambda}{2m}\\sum_{j=1}^{n} \\theta^{2}_j$$\n",
    "\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial\\theta_j}=\\frac{1}{m}X^T(g(X\\theta)-y)+\\frac{\\lambda}{m}\\theta_j$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funCosteReg(theta, x, y, lamb):\n",
    "    return -1/len(x) * (((np.log( g(x.dot(theta)) )).T).dot(y) +\n",
    "                        ((np.log( 1 - g(x.dot(theta)) )).T).dot(1-y) +\n",
    "                        (lamb/(2*len(x))*(np.sum(theta))**2))\n",
    "\n",
    "def gradientReg(theta, x, y, lamb):\n",
    "    return 1/len(x) * (x.T).dot(g(x.dot(theta)) - y) + (lamb/len(x))*theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASIFICACIÓN DE UNO FRENTE A TODOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a entrenar un clasificador por regresión logística para cada una de las 10 clases del conjunto de datos. Lo implementaremos con una función que devuelve una matriz $\\theta$ de orden Kx(N+1) donde cada fila de la matriz corresponde a los parámetros aprendidos para el clasificador de una de las clases. Esto lo realizaremos mediante una función (clasificadorClase) que devuelve el vector $\\theta$ aprendido para una determinada clase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificadorClase(X, y, num_etiquetas, reg):\n",
    "    \n",
    "    thetaAux = np.zeros((len(X[0])))\n",
    "    result = opt.fmin_tnc(func=funCosteReg, x0=thetaAux, fprime=gradientReg,\n",
    "                          args=(X, y.ravel(), reg))\n",
    "    \n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función oneVsAll es la encargada de devolver la matriz $\\theta$. En ella se crea una matriz de ceros de orden Kx(N+1) y mediante un bucle que selecciona que ejemplos de entrenamiento pertenecen a una clase determinada, indicada por el indice *i*.\n",
    "Con esto lo que hacemos es poner a 1, en el vector *yaux*, la clase que queremos clasificar y el resto a 0. Una vez hecho esto, realizamos la regresión llamando a la funcion *clasificadorClase* que optimiza los parametros $\\theta$, necesarios para poder separar los ejemplos de entrenamiento de la clase que estamos clasificando, del resto de clases.\n",
    "Esto lo realizamos con todas las clases para obtener finalmente la matriz que debemos devolver.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneVsAll(X, y, num_etiquetas, reg):\n",
    "    # Matriz theta de orden Kx(N+1) inicializada con 0's, donde K es el\n",
    "    # número de clases y N+1 el número de etiquetas\n",
    "    theta = np.zeros((num_etiquetas, len(X[0])))\n",
    "\n",
    "    for i in range(1, num_etiquetas + 1):\n",
    "        yaux = np.where(y == i, 1, 0)\n",
    "        thetaAux = np.zeros((len(X[0])))\n",
    "        theta[i-1, :] = clasificadorClase(X, yaux, num_etiquetas, reg)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz theta: [[ 0.00000000e+00  0.00000000e+00  1.13365698e-04 ...  7.49964770e-03\n",
      "  -6.86389008e-09  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -2.46378207e-04 ...  1.57012381e-02\n",
      "  -1.68189112e-03  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.49118731e-04 ... -1.46300053e-05\n",
      "  -3.54386814e-07  0.00000000e+00]\n",
      " ...\n",
      " [ 0.00000000e+00  0.00000000e+00 -2.38067998e-04 ... -1.67848254e-02\n",
      "   1.78009062e-03  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.24782815e-06 ... -4.06004280e-02\n",
      "   3.96151675e-03  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.59755341e-07 ... -2.60753472e-04\n",
      "   2.25408480e-05  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "theta_opt = oneVsAll(X, y, 10, 0.1)\n",
    "print(\"Matriz theta: \" + str(theta_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hemos entrenado el clasificador y hemos obtenido las $\\theta$ optimizadas. Vamos a comprobar cuantos ejemplos de entrenamiento clasifica correctamente. Para ello, para cada ejemplo de entrenamiento calculamos la probabilidad de que pertenezca a una clase u otra y obtenemos los índices de los máximos de cada fila. Este índice coincide con la clase que ha obtenido la mayor probabilidad.\n",
    "Comparamos estos indices con el vector *y* que contiene las etiquetas que se han asignado a cada imagen, y obtenemos un vector con *True* o *False* dependiendo de si los elementos coindicen entre sí o no.\n",
    "Por último contamos la cantidad de *True* que hay en el vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de clasificados correctamente: 95.92%\n"
     ]
    }
   ],
   "source": [
    "#Calculamos la probabilidad de que pertenezca a una clase u otra\n",
    "probabilidad = g(X.dot(theta_opt.T))\n",
    "\n",
    "#Obtenemos el índice del elemento con mayor probabilidad\n",
    "indices = np.argmax(probabilidad, axis=1)\n",
    "indices+=1\n",
    "\n",
    "#Vector de booleanos\n",
    "porcentaje = (indices == y.ravel())\n",
    "clasificados = porcentaje[porcentaje == True]\n",
    "\n",
    "print(\"Porcentaje de clasificados correctamente: \" \n",
    "      + str((len(clasificados)/len(X))*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso usaremos unos pesos proporcionados para crear una red neuronal y evaluar su precisión.\n",
    "\n",
    "Para esto leemos el fichero *ex3weights.mat*, que contine las $\\theta$s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = loadmat('ex3weights.mat')\n",
    "theta1, theta2 = weights['Theta1'], weights['Theta2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora crearemos una red neuronal para que calcule la probabilidad de que cada caso de prueba sea uno de los números.\n",
    "\n",
    "La red neuronal está compuesta por 400 nodos en la capa externa y 25 en la oculta, terminando con 10 valores como resultado de la operación.\n",
    "\n",
    "Para esto utilizaremos operaciones matriciales que agilicen el proceso (ya que se tratan de enormes cantidades de datos).\n",
    "\n",
    "Para obtener los resultados de la primera capa multiplicamos las matrices $x$ y $\\theta_1^T$ y las metemos en la función sigmoide (*g()*) que ya habíamos declarado. De este modo tenemos una matriz **z** con los nodos de la capa oculta.\n",
    "\n",
    "Para la segunda capa multiplicamos la matriz **z** por $\\theta_2^T$, metiéndolas también en *g()* y obteniendo así *h(x)*, una matriz de $5000x10$, siendo las filas los casos de prueba y las columnas las probabilidades de pertenecer a cada número."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redNeuronal(x) :\n",
    "    one = np.ones((len(x), 1))\n",
    "    x = np.hstack([one, x])\n",
    "\n",
    "    z = g(x.dot(theta1.T))\n",
    "    \n",
    "    one = np.ones((len(z), 1))\n",
    "    z = np.hstack([one, z])\n",
    "   \n",
    "    return g(z.dot(theta2.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente vamos a calcular el porcentaje de acierto de la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de clasificados correctamente: 97.52%\n"
     ]
    }
   ],
   "source": [
    "#Calculamos la probabilidad de que pertenezca a una clase u otra\n",
    "probabilidades = redNeuronal(X)\n",
    "\n",
    "#Obtenemos el índice del elemento con mayor probabilidad\n",
    "maximos = np.argmax(probabilidades, axis=1)\n",
    "maximos += 1\n",
    "\n",
    "#Vector de booleanos\n",
    "porcentaje = (maximos == y.ravel())\n",
    "\n",
    "clasificados = porcentaje[porcentaje == True]\n",
    "\n",
    "print(\"Porcentaje de clasificados correctamente: \" \n",
    "      + str(len(clasificados)/len(X)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar, el porcentaje de acierto es del 97.52%, considerablemente superior al anterior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
