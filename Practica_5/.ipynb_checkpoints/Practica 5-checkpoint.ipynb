{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Alumnos**: *Adrián Ogáyar Sanchez y Arturo Barbero Pérez*\n",
    "\n",
    ">**Grupo**: *11*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal regularizada: sesgo y varianza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de esta práctica es comprobar los efectos del sesgo y la varianza.\n",
    "Para esto aplicaremos regresión lineal regularizada para aprender una hipótesis sesgada, que no es capaz de\n",
    "clasificar correctamente a los ejemplos de entrenamiento, y a continuación usaremos de nuevo la\n",
    "regresión lineal para sobre-ajustar los datos de entrenamiento a un polinomio de grado superior.\n",
    "\n",
    "Comenzamos importando las librerías necesarias. Todas ellas han sido utilizadas y explicadas en prácticas anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as ptl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal regularizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuamos cargando los datos del fichero *ex5data1.mat* Este fichero contiene una serie de datos de entrenamiento, datos de validación y datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('ex5data1.mat')\n",
    "\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "Xtest = data['Xtest']\n",
    "ytest = data['ytest']\n",
    "Xval = data['Xval']\n",
    "yval = data['yval']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras cargar los datos debemos crear una función para calcular el coste y el gradiente de la regresión lineal regularizada que siguen esta expresión:\n",
    "$$J(\\theta)=\\frac{1}{2m}(\\sum^m_{i=1}(h_\\theta(x^{(i)})-y^{(i)})^2)+\\frac{\\lambda}{2m}(\\sum^n_{j=1}\\theta^2_j)$$\n",
    "$$\\frac{\\delta J(\\theta)}{\\delta\\theta_0}=\\frac{1}{m}\\sum^m_{i=1}(h_\\theta(x^{(i)})-y^{(i)})x^{(i)}_j\\quad para\\: j = 0$$\n",
    "$$\\frac{\\delta J(\\theta)}{\\delta\\theta_0}=\\frac{1}{m}\\sum^m_{i=1}(h_\\theta(x^{(i)})-y^{(i)})x^{(i)}_j+\\frac{\\lambda}{m}\\theta_j\\quad para\\: j\\ge 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = lambda x, t : t.dot(x.T)\n",
    "\n",
    "def coste(x, y, theta) :    \n",
    "    return 1/(2*len(x)) * (np.sum((h(x, theta)-y)**2))\n",
    "\n",
    "def costeReg(x, y, theta, lamb) :\n",
    "    return coste(x,y,theta) + lamb/(2*len(x))*np.sum(theta[1:]**2)\n",
    "\n",
    "def gradiente(x, y, theta, lamb) :\n",
    "    grad = 1/len(x) * np.matmul((h(x, theta)-y),x)\n",
    "    grad[1:] += (theta[1:] * lamb/len(x))\n",
    "    return grad\n",
    "\n",
    "def regLinealReg(x, y, theta, lamb) :\n",
    "    y = y.ravel()\n",
    "    one = np.ones((len(x), 1))\n",
    "    x = np.hstack([one, x])\n",
    "    return(costeReg(x,y,theta,lamb), gradiente(x,y,theta,lamb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.ones((2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303.9931922202643, array([-15.30301567, 598.25074417]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regLinealReg(X, y, theta, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curvas de Aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La hipótesis elegida en el apartado anterior, una recta, es demasiado simple para ajustarse a los ejemplos de entrenamiento y por ello predice valores sesgados a la recta. Cuando los ejemplos vienen dados por más atributos no es posible tener una representación gráfica tan evidente. Por ello, se utilizan las curvas de aprendizae para identificar situaciones de sub-ajuste (sesgo) o de sobre-ajuste (varianza).\n",
    "\n",
    "Para generar las curvas de aprendizaje, tenemos que repetir el entrenamiento por regresión lineal del apartado anterior utilizando diferentes subconjuntos de los datos de entrenamiento. \n",
    "\n",
    "Una vez realizado el entrenamiento para ajustarse al subconjunto X[0:i] e y[0:i], tenemos que evaluar el error del resultado aplicado a ese mismo subconjunto, así como el error al clasificar a todos los ejemplos del conjunto de validación (Xval e yval). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "regLinealReg() missing 2 required positional arguments: 'theta' and 'lamb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5bbe235a0ac7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mregLinealReg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: regLinealReg() missing 2 required positional arguments: 'theta' and 'lamb'"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(X)):\n",
    "    \n",
    "    regLinealReg(X[0:i], y[0:i], )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
